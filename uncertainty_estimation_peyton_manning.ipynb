{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ourownstory/neural_prophet/blob/master/example_notebooks/uncertainty_estimation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Uncertainty Estimation\n",
    "NeuralProphet allows the modelling of overall prediction intervals. We use the standard pinball loss function in the model to estimate different quantiles specified by the user, without any other distributional assumptions. Here, we demonstrate this feature using the peyton manning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep neuralprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch                 1.11.0\n",
      "torch-lr-finder       0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if 'google.colab' in str(get_ipython()):\n",
    "#     !pip install git+https://github.com/ourownstory/neural_prophet.git # may take a while\n",
    "#     #!pip install neuralprophet # much faster, but may not have the latest upgrades/bugfixes\n",
    "#     data_location = \"https://raw.githubusercontent.com/ourownstory/neural_prophet/master/\"\n",
    "# else:\n",
    "#     data_location = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-10</td>\n",
       "      <td>9.590761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-11</td>\n",
       "      <td>8.519590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-12</td>\n",
       "      <td>8.183677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds         y\n",
       "0  2007-12-10  9.590761\n",
       "1  2007-12-11  8.519590\n",
       "2  2007-12-12  8.183677"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "# set_log_level(\"ERROR\")\n",
    "df = pd.read_csv(data_location + \"example_data/wp_log_peyton_manning.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Functionality\n",
    "For estimating the 0.25 and 0.75 quantiles, the NeuralProphet object can be created as follows by\n",
    "specifying the required quantiles (in between (0,1)) in a list. The 0.5 quantile is always modelled by default.\n",
    "The progression of the PinballLoss values through the training epochs can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    quantiles=[0.9, 0.1]\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")\n",
    "metrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(df, periods=30, n_historic_predictions=100)\n",
    "forecast = m.predict(df=future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecasts df now has columns designated for the different quantiles of the output yhat1. For the\n",
    "components, only the 50% quantile is shown in the current state of this feature. The uncertainty bands can\n",
    "be plotted as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_forec = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly the components and parameters can be plotted for the 0.5th quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig_comp = m.plot_components(forecast)\n",
    "fig_param = m.plot_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other features of the model, such as events, regressors, regularization etc. can be used along with\n",
    "the quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "playoffs = pd.DataFrame({\n",
    "    'event': 'playoff',\n",
    "    'ds': pd.to_datetime([\n",
    "        '2008-01-13', '2009-01-03', '2010-01-16',\n",
    "        '2010-01-24', '2010-02-07', '2011-01-08',\n",
    "        '2013-01-12', '2014-01-12', '2014-01-19',\n",
    "        '2014-02-02', '2015-01-11', '2016-01-17',\n",
    "        '2016-01-24', '2016-02-07',\n",
    "    ]),\n",
    "})\n",
    "\n",
    "superbowls = pd.DataFrame({\n",
    "    'event': 'superbowl',\n",
    "    'ds': pd.to_datetime([\n",
    "        '2010-02-07', '2012-02-05', '2014-02-02',\n",
    "        '2016-02-07',\n",
    "    ]),\n",
    "})\n",
    "\n",
    "events_df = pd.concat((playoffs, superbowls))\n",
    "\n",
    "# NeuralProphet Object\n",
    "m = NeuralProphet(\n",
    "    quantiles=[0.9, 0.1],\n",
    "    seasonality_reg=1.5,\n",
    ")\n",
    "\n",
    "# set the model to expect these events\n",
    "m = m.add_events([\"playoff\", \"superbowl\"], regularization=0.1)\n",
    "\n",
    "# create the data df with events\n",
    "history_df = m.create_df_with_events(df, events_df)\n",
    "metrics = m.fit(history_df, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(history_df, events_df, periods=30, n_historic_predictions=100)\n",
    "forecast = m.predict(df=future)\n",
    "fig_forec = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Base Loss Functions\n",
    "In the standard pinball loss, the base error is just the difference between the actuals and the\n",
    "predicted. However, in NeuralProphet we provide the user, the capability to define other losses for the\n",
    "base loss such as `MSE`, `MAE` and `Huber`. This can be done as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    loss_func=\"Huber\",\n",
    "    quantiles=[0.9, 0.1]\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(df, periods=30, n_historic_predictions=100)\n",
    "forecast = m.predict(df=future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Auto-Regression\n",
    "Overall uncertainty can be modelled with the AR-Net as well. The only difference is that,\n",
    "to plot the forecasts, always a forecast step needs to be specified using the `highlight_nth_step_ahead_of_each_forecast` function. The uncertainty bands are plotted\n",
    "for that particular forecast step, since otherwise the plot can look quite cluttered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = NeuralProphet(\n",
    "    n_lags=5,\n",
    "    n_forecasts=3,\n",
    "    quantiles=[0.9, 0.1]\n",
    ")\n",
    "metrics = m.fit(df, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(df, periods=3, n_historic_predictions=10)\n",
    "forecast = m.predict(df=future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m.highlight_nth_step_ahead_of_each_forecast(2)\n",
    "fig_last_forec = m.plot_last_forecast(forecast, include_previous_forecasts=3)\n",
    "fig_forec = m.plot(forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9896633dd2687027a97d37c5dc67af73c090796eacc50847f77e025856fff9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
